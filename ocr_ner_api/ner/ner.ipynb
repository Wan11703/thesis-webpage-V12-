{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a390df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mark\\OneDrive\\Desktop\\thesis-webpage\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Drug Names: ['aspirin', 'paracetamol', 'ibuprofen']\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Define the path to your fine-tuned model\n",
    "model_path = \"c:/Users/Mark/OneDrive/Desktop/thesis-webpage/ner/ner_biobert/checkpoint-420\"\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = BertForTokenClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Example text for NER\n",
    "text = \"Aspirin and Paracetamol is a commonly used drug for pain relief.Ibuprofen is another common pain reliever.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get predictions\n",
    "logits = outputs.logits\n",
    "predictions = torch.argmax(logits, dim=2)\n",
    "\n",
    "# Decode predictions\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
    "\n",
    "# Reconstruct words and their labels\n",
    "word_labels = []\n",
    "current_word = \"\"\n",
    "current_label = \"O\"\n",
    "\n",
    "for token, label in zip(tokens, labels):\n",
    "    if token.startswith(\"##\"):  # Subword token\n",
    "        current_word += token[2:]  # Append subword without \"##\"\n",
    "    else:\n",
    "        if current_word:  # Save the previous word and its label\n",
    "            word_labels.append((current_word, current_label))\n",
    "        current_word = token  # Start a new word\n",
    "        current_label = label\n",
    "\n",
    "# Add the last word\n",
    "if current_word:\n",
    "    word_labels.append((current_word, current_label))\n",
    "\n",
    "# Merge consecutive B-DRUG and I-DRUG tokens\n",
    "merged_drug_names = []\n",
    "current_drug = \"\"\n",
    "\n",
    "for word, label in word_labels:\n",
    "    if label == \"B-DRUG\":\n",
    "        if current_drug:  # Save the previous drug name\n",
    "            merged_drug_names.append(current_drug)\n",
    "        current_drug = word  # Start a new drug name\n",
    "    elif label == \"I-DRUG\":\n",
    "        current_drug += word  # Append to the current drug name\n",
    "    else:\n",
    "        if current_drug:  # Save the previous drug name\n",
    "            merged_drug_names.append(current_drug)\n",
    "            current_drug = \"\"\n",
    "\n",
    "# Add the last drug name if any\n",
    "if current_drug:\n",
    "    merged_drug_names.append(current_drug)\n",
    "\n",
    "# Print the merged drug names\n",
    "print(\"Merged Drug Names:\", merged_drug_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
